import streamlit as st
import pandas as pd
import os
import io
import zipfile
import time
import datetime

# --- é¡µé¢åŸºç¡€è®¾ç½® ---
st.set_page_config(
    page_title="æ•°æ®è½¬æ¢ä¸æ‹†åˆ†å·¥å…·",
    page_icon="âœ¨",
    layout="wide"
)

# --- ç›®æ ‡è¡¨æ ¼çš„å­—æ®µåˆ—è¡¨ ---
TARGET_COLUMNS = [
    'è£…è´§å•ç¼–å·', 'å¸è´§å•ç¼–å·', 'å¸æœº', 'æ‰‹æœºå·', 'è½¦ç‰Œå·', 'æŒ‚è½¦', 
    'è£…è½¦é‡(å¨)', 'å¸è´§é‡(å¨)', 'è£…è½¦æ—¶é—´', 'å¸è´§æ—¶é—´', 'å¸æœºè¿è´¹å•ä»·', 
    'å‘è´§å•ä½åç§°', 'å‘è´§å•ä½è¯ä»¶å·', 'å‘è´§ç‚¹ç®€ç§°', 'å‘è´§(çœ)', 'å‘è´§(å¸‚)', 
    'å‘è´§(åŒº)', 'å‘è´§è¯¦ç»†åœ°å€', 'å‘è´§è”ç³»äºº', 'å‘è´§è”ç³»äººç”µè¯', 
    'æ”¶è´§å•ä½åç§°', 'æ”¶è´§å•ä½è¯ä»¶å·', 'æ”¶è·åœ°å€ç®€ç§°', 'æ”¶è´§(çœ)', 'æ”¶è´§(å¸‚)', 
    'æ”¶è´§(åŒº)', 'æ”¶è´§è¯¦ç»†åœ°å€', 'æ”¶è´§è”ç³»äºº', 'æ”¶è´§è”ç³»äººç”µè¯'
]

def transform_and_process(uploaded_file, group_by_column, log_container):
    """
    è¯»å–ã€è½¬æ¢ã€æ‹†åˆ†å¹¶æ‰“åŒ…Excelæ–‡ä»¶ã€‚
    """
    logs = []
    def log_message(message):
        logs.append(message)
        log_container.markdown("```\n" + "\n".join(logs) + "\n```")

    try:
        source_filename = os.path.splitext(uploaded_file.name)[0]
        log_message(f"å‡†å¤‡å¤„ç†æ–‡ä»¶: {uploaded_file.name}")
        
        df_source = pd.read_excel(uploaded_file)
        total_rows = len(df_source)
        log_message(f"âœ… æˆåŠŸè¯»å–æºæ–‡ä»¶ï¼Œå…±åŒ…å« {total_rows} æ¡æ•°æ®ã€‚")

        log_message("â³ å¼€å§‹è¿›è¡Œæ•°æ®ç»“æ„è½¬æ¢...")
        
        new_rows = []
        for index, row in df_source.iterrows():
            new_row = {}
            # å­—æ®µæ˜ å°„
            new_row['å¸æœº'] = row.get('å¸æœºå§“åï¼ˆæ”¶æ¬¾äººï¼‰')
            new_row['æ‰‹æœºå·'] = row.get('å¸æœºæ‰‹æœºå·ç ï¼ˆæ”¶æ¬¾äººï¼‰')
            new_row['è½¦ç‰Œå·'] = row.get('è½¦ç‰Œ')
            
            # æ—¶é—´å­—æ®µæ ¼å¼åŒ–å¤„ç†
            for col_name in ['è£…è½¦æ—¶é—´', 'å¸è´§æ—¶é—´']:
                time_val = row.get(col_name)
                if pd.notna(time_val) and isinstance(time_val, (pd.Timestamp, datetime.datetime)):
                    new_row[col_name] = time_val.strftime('%Y/%m/%d %H:%M')
                else:
                    new_row[col_name] = time_val
            
            # ==================== æ–°å¢çš„æ˜ å°„è§„åˆ™ ====================
            # ä»æºè¡¨è·å–â€œè´§ä¸»åç§°â€
            è´§ä¸»åç§°_val = row.get('è´§ä¸»åç§°')
            # å°†å…¶åŒæ—¶èµ‹å€¼ç»™ç›®æ ‡è¡¨çš„ä¸‰ä¸ªå­—æ®µ
            new_row['æ”¶è´§å•ä½åç§°'] = è´§ä¸»åç§°_val
            new_row['æ”¶è·åœ°å€ç®€ç§°'] = è´§ä¸»åç§°_val
            new_row['æ”¶è´§è”ç³»äºº'] = è´§ä¸»åç§°_val
            # =========================================================

            # æ•°é‡æ˜ å°„
            è£…è½¦é‡ = row.get('å¸æœºè£…è´§æ•°é‡')
            new_row['è£…è½¦é‡(å¨)'] = è£…è½¦é‡
            new_row['å¸è´§é‡(å¨)'] = è£…è½¦é‡
            
            # è®¡ç®—å­—æ®µ
            é‡Œç¨‹ = pd.to_numeric(row.get('é‡Œç¨‹'), errors='coerce')
            å•ä»· = pd.to_numeric(row.get('å¸æœºè¿è¾“å•ä»·ï¼ˆäººæ°‘å¸ï¼‰'), errors='coerce')
            if pd.notna(é‡Œç¨‹) and pd.notna(å•ä»·):
                new_row['å¸æœºè¿è´¹å•ä»·'] = é‡Œç¨‹ * å•ä»·
            else:
                new_row['å¸æœºè¿è´¹å•ä»·'] = None
            
            new_row[group_by_column] = row.get(group_by_column)
            new_rows.append(new_row)
        
        df_target = pd.DataFrame(new_rows)
        df_target = df_target.reindex(columns=TARGET_COLUMNS + [group_by_column])

        log_message("âœ… æ•°æ®ç»“æ„è½¬æ¢å®Œæˆï¼")
        log_message("-" * 40)
        
        unique_groups = df_source[group_by_column].dropna().unique()
        log_message(f"ğŸ” åœ¨â€œ{group_by_column}â€åˆ—ä¸­å‘ç° {len(unique_groups)} ä¸ªç‹¬ç«‹çš„é¡¹ç›®ï¼Œå‡†å¤‡å¼€å§‹æ‹†åˆ†...")
        
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
            for i, group_value in enumerate(unique_groups, 1):
                source_group_df = df_source[df_source[group_by_column] == group_value]
                source_group_rows = len(source_group_df)
                
                target_group_df = df_target[df_target[group_by_column] == group_value]
                final_df_to_save = target_group_df.drop(columns=[group_by_column])

                safe_filename = "".join([c for c in str(group_value) if c.isalnum() or c in (' ', '_', '-')]).rstrip()
                if not safe_filename:
                    safe_filename = f"æœªå‘½ååŒºåŸŸ_{i}"
                
                output_filename_in_zip = f"{safe_filename}.xlsx"
                
                excel_buffer = io.BytesIO()
                final_df_to_save.to_excel(excel_buffer, index=False, engine='openpyxl')
                excel_buffer.seek(0)
                
                zf.writestr(output_filename_in_zip, excel_buffer.read())
                
                log_message(f"({i}/{len(unique_groups)}) å·²ç”Ÿæˆæ–‡ä»¶: {output_filename_in_zip} (æºè¡¨è¡Œæ•°: {source_group_rows}, æ–°è¡¨è¡Œæ•°: {len(final_df_to_save)})")
                time.sleep(0.01)

        log_message("-" * 40)
        log_message("âœ… æ‰€æœ‰è¡¨æ ¼æ‹†åˆ†å®Œæˆï¼")
        zip_buffer.seek(0)
        return zip_buffer, source_filename

    except Exception as e:
        st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        log_message(f"âŒ é”™è¯¯è¯¦æƒ…: {e}")
        return None, None

# --- Streamlit ç•Œé¢å¸ƒå±€ (è¿™éƒ¨åˆ†ä¿æŒä¸å˜) ---
st.title("âœ¨ è¡¨æ ¼æ•°æ®è½¬æ¢ä¸æŒ‰åŒºåŸŸæ‹†åˆ†å·¥å…·")
st.markdown("""
ä¸Šä¼ ä¸€ä¸ªç‰¹å®šæ ¼å¼çš„æºExcelè¡¨ï¼Œå·¥å…·å°†ï¼š
1.  æŒ‰ç…§é¢„è®¾è§„åˆ™**è½¬æ¢æ•°æ®ç»“æ„**ã€‚
2.  æ ¹æ® **â€œåŒºåŸŸâ€** å­—æ®µå¯¹æ•°æ®è¿›è¡Œåˆ†ç±»ã€‚
3.  ä¸ºæ¯ä¸ªåŒºåŸŸç”Ÿæˆä¸€ä¸ªç‹¬ç«‹çš„Excelæ–‡ä»¶ï¼Œå¹¶æ‰“åŒ…æˆZIPä¾›æ‚¨ä¸‹è½½ã€‚
""")
st.markdown("---")

uploaded_file = st.file_uploader("ä¸Šä¼ æ‚¨çš„æºæ•°æ® Excel è¡¨", type=['xlsx'])

if uploaded_file is not None:
    st.subheader("1. ç¡®è®¤æ‹†åˆ†è§„åˆ™")
    
    group_by_column_fixed = "åŒºåŸŸ"
    st.info(f"æœ¬å·¥å…·å°†é»˜è®¤æ ¹æ® **`{group_by_column_fixed}`** åˆ—è¿›è¡Œæ‹†åˆ†ã€‚")

    st.subheader("2. å¼€å§‹å¤„ç†å¹¶æŸ¥çœ‹æ—¥å¿—")
    log_container = st.empty()
    log_container.info("å‡†å¤‡å°±ç»ªï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹å¤„ç†ã€‚")

    if st.button("ğŸš€ å¼€å§‹è½¬æ¢å¹¶æ‹†åˆ†", use_container_width=True):
        log_container.empty()
        
        zip_buffer, source_filename = transform_and_process(uploaded_file, group_by_column_fixed, log_container)
        
        if zip_buffer and source_filename:
            st.success("ğŸ‰ å¤„ç†å®Œæˆï¼å¯ä»¥ä¸‹è½½ç»“æœäº†ã€‚")
            
            st.subheader("3. ä¸‹è½½ç»“æœ")
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½è½¬æ¢åçš„ç»“æœ (ZIP)",
                data=zip_buffer,
                file_name=f'{source_filename}_æŒ‰åŒºåŸŸæ‹†åˆ†.zip',
                mime='application/zip',
                use_container_width=True
            )
else:
    st.info("è¯·ä¸Šä¼ ä¸€ä¸ª .xlsx æ–‡ä»¶ä»¥å¼€å§‹ã€‚")

st.markdown("---")
st.write("ç”± AI ä¸å¼€å‘è€…å…±åŒæ„å»ºçš„å®šåˆ¶åŒ–å·¥å…·ã€‚")
